# -*- coding: utf-8 -*-
"""mimiciii_nlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o3pBnrrWlLETo2ncxNp7ZZaFSNOBfbPK

# AI in Healthcare - Assignment 1: MIMIC-III Natural Language Processing

### Connect to MIMIC-III Through Google BigQuery
"""

# Auth is meant for Google Colab. May have to set up dataset locally or create your own Big Query dataset
# Standard Jupyter Notebook may have a different setup process
from google.colab import auth
from google.cloud import bigquery
bq_client = bigquery.Client(project = "project-id")
auth.authenticate_user()

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # Import libraries
# !pip install spacy==3.7.5
# import gensim.downloader as api
# from gensim.models.word2vec import Word2Vec
# import numpy as np
# import pandas as pd
# from sklearn.manifold import TSNE
# import matplotlib.pyplot as plt
# from spacy import displacy
# import random
# import re
# import spacy
# from tqdm import tqdm
# 
# pretrained_model = api.load("glove-wiki-gigaword-50")
# nlp_spacy = spacy.load('en_core_web_sm')
#

"""### Preprocess Data"""

# Query Nueromyelitis Optica Spectrum Disorder medical notes and keep unique texts
ms_notes_df = bq_client.query('''
SELECT ne.subject_id, ne.chartdate, ne.category, ne.text, d.icd9_code, icd.long_title AS diagnosis
FROM `physionet-data.mimiciii_notes.noteevents` AS ne
JOIN `physionet-data.mimiciii_clinical.diagnoses_icd` AS d ON ne.subject_id = d.subject_id
JOIN `physionet-data.mimiciii_clinical.d_icd_diagnoses` AS icd ON d.icd9_code = icd.icd9_code
WHERE d.icd9_code = '3410'
ORDER BY ne.subject_id, ne.chartdate;
''').to_dataframe()

ms_notes_df = ms_notes_df.drop_duplicates(subset=['text'], keep='first')

# Clean the text
nmosd_notes = []
for _, row in ms_notes_df.iterrows():
    text = row['text']
    text = text.strip()
    text = re.sub(r'\n+', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\[\*\*.*?\*\*\]', '', text)
    text = re.sub(r'[^a-zA-Z0-9,.!?% ]', '', text)
    text = re.sub(r'\s{2,}', ' ', text)
    text = re.sub(r'\s+([.,!?%])', r'\1', text)
    nmosd_notes.append(text)

"""### Part 1 - NLP of NMOSD patient notes using Spacy"""

# Entity visualization
for i in range(3):
    doc = nlp_spacy(nmosd_notes[i])
    displacy.render(doc, style='ent', jupyter=True)
    print("---------------------------")

# Create corpus
corpus_spacy = []
for row in tqdm(range(len(nmosd_notes))):
  str_tokens = []
  tokens = nlp_spacy(nmosd_notes[row]).ents
  for i in range(0, len(tokens)):
    str_tokens.append(tokens[i].text)
  corpus_spacy.append(list(str_tokens))

# Create W2V model
model_spacy = Word2Vec(corpus_spacy, min_count=1)

# Show W2V for 'diverticulitis'
model_spacy.wv['diverticulitis']

# Find most similiar words to 'diverticulitis'
model_spacy.wv.similar_by_word('diverticulitis')

# Function to create TSNE plot
def tsne_plot(model, words, preTrained=False):
    labels = []
    tokens = []

    for word in words:
        if preTrained == True:
            if word in model:
                tokens.append(model[word] if preTrained else model.wv[word])
                labels.append(word)
        else:
            tokens.append(model[word] if preTrained else model.wv[word])
            labels.append(word)

    tokens = np.array(tokens)
    tsne_model = TSNE(perplexity=30, early_exaggeration=12, n_components=2, init='pca', max_iter=250, random_state=23)
    new_values = tsne_model.fit_transform(tokens)

    x, y = zip(*new_values)

    plt.figure(figsize=(16, 16))
    for i in range(len(x)):
        plt.scatter(x[i], y[i])
        plt.annotate(labels[i], xy=(x[i], y[i]), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')
    plt.show()

# Plot TSNE
vocabs = model_spacy.wv.key_to_index.keys()
words = np.array(list(vocabs))
tsne_plot(model_spacy, words)

# Create corpus for pretrained model
corpus_in_pretrained_model = []
for word in vocabs:
  if word in pretrained_model:
    corpus_in_pretrained_model.append(word)

# Plot TSNE using pretrained model
tsne_plot(pretrained_model, corpus_in_pretrained_model, preTrained=True)

"""### Part 2 - NLP of NMOSD patient notes using SciSpacy"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install scispacy
# !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz
# import scispacy
# nlp_scispacy = spacy.load('en_core_sci_md')
#

# Entity visualization
for i in range(3):
    doc = nlp_scispacy(nmosd_notes[i])
    displacy.render(doc, style='ent', jupyter=True)
    print("---------------------------")

# Create corpus
corpus_scispacy = []
for row in tqdm(range(len(nmosd_notes))):
  str_tokens = []
  tokens = nlp_scispacy(nmosd_notes[row]).ents
  for i in range(0, len(tokens)):
    str_tokens.append(tokens[i].text)
  corpus_scispacy.append(list(str_tokens))

# Create W2V model
model_scispacy = Word2Vec(corpus_scispacy, min_count=1)

# Show W2V for 'diverticulitis'
model_scispacy.wv['diverticulitis']

# Find most similiar words to 'diverticulitis'
model_scispacy.wv.similar_by_word('diverticulitis')

# Plot TSNE
vocabs = model_scispacy.wv.key_to_index.keys()
words = np.array(list(vocabs))
tsne_plot(model_scispacy, words)

# Create corpus for pretrained model
corpus_in_pretrained_model = []
for word in vocabs:
  if word in pretrained_model:
    corpus_in_pretrained_model.append(word)

# Plot TSNE using pretrained model
tsne_plot(pretrained_model, corpus_in_pretrained_model, preTrained=True)

"""### Part 3 - NLP of NMOSD patient notes using BlueBert"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install torch transformers sentencepiece
# from transformers import AutoTokenizer, AutoModel, pipeline
# import torch
# tokenizer = AutoTokenizer.from_pretrained("bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12")
# model = AutoModel.from_pretrained("bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12")
# ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer)
# nlp_bluebert = spacy.blank("en")
#

# Create corpus
corpus_bluebert = []
for text in tqdm(nmosd_notes):
    tokens = tokenizer.tokenize(text)
    corpus_bluebert.append(tokens)

# Get embeddings
def get_bluebert_embeddings(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()

bluebert_embeddings = np.array([get_bluebert_embeddings(text) for text in nmosd_notes])

# Create TSNE plot
def tsne_plot_bert(embeddings, labels):
    tsne_model = TSNE(perplexity=30, early_exaggeration=12, n_components=2, init='pca', max_iter=250, random_state=23)
    new_values = tsne_model.fit_transform(embeddings)

    x, y = zip(*new_values)

    plt.figure(figsize=(16, 16))
    for i in range(len(x)):
        plt.scatter(x[i], y[i])
        plt.annotate(labels[i], xy=(x[i], y[i]), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')
    plt.show()

# Plot TSNE
words = list(set([word for tokens in corpus_bluebert for word in tokens]))
tsne_plot_bert(bluebert_embeddings, words)

# Create corpus for pretrained model.
corpus_pretrained = [word for word in words if word in pretrained_model]
glove_embeddings = np.array([pretrained_model[word] for word in corpus_pretrained])

# Plot TSNE using pretrained model
tsne_plot_bert(glove_embeddings, corpus_pretrained)